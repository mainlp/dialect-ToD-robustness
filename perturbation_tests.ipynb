{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb2fece9-22f6-4a7d-ab62-44152bdedbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b015c024-53ca-4f3d-b836-ebb64ea0b94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf CharSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "467af3b6-8a2a-4eb5-9667-1142e5a035bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-13 16:14:32 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b3e1a8766d4459b3ed2cb684f68ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.5.1.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-13 16:14:32 WARNING: Language de package default expects mwt, which has been added\n",
      "2023-09-13 16:14:33 INFO: Loading these models for language: de (German):\n",
      "==========================\n",
      "| Processor | Package    |\n",
      "--------------------------\n",
      "| tokenize  | gsd        |\n",
      "| mwt       | gsd        |\n",
      "| pos       | gsd_charlm |\n",
      "==========================\n",
      "\n",
      "2023-09-13 16:14:33 INFO: Using device: cpu\n",
      "2023-09-13 16:14:33 INFO: Loading: tokenize\n",
      "2023-09-13 16:14:33 INFO: Loading: mwt\n",
      "2023-09-13 16:14:33 INFO: Loading: pos\n",
      "2023-09-13 16:14:33 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: [Errno 39] Directory not empty: 'CharSplit'\n"
     ]
    }
   ],
   "source": [
    "from dialect_perturbations import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf5e35a3-ca0a-4e69-a573-57288cd50aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Beruf vom altem Mann .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/work/artemova/dialect-robust/DERBI/Tools.py:91: Warning: Provided tags were not found in labels scheme. Some features were set as default.\n",
      "Result features are \"Case=Dat|Declination=Strong|Degree=Pos|Gender=Masc|Number=Sing\". You can specify desired features if you wish.\n",
      "Labels scheme is available at: https://github.com/maxschmaltz/DERBI/blob/main/meta/LabelsScheme.json.\n",
      "  warnings.warn('Provided tags were not found in labels scheme. Some features were set as default.\\nResult features are \"' +\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Der Beruf des alten Mannes .\"\n",
    "tokens = sentence.split()\n",
    "tags = [\"O\"] * len(tokens)\n",
    "\n",
    "\n",
    "perturbed_tokens, perturbed_tags, perturbed = perturb_genitive_to_dativ(tokens, tags)\n",
    "print(' '.join(perturbed_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "375e9c9e-8657-48c8-8eea-8d1b80350238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruf Keira ihr Sohn an .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Ruf Keiras Sohn an .\"\n",
    "tokens = sentence.split()\n",
    "tags = [\"O\"] * len(tokens)\n",
    "tags[1] = 'B-person'\n",
    "\n",
    "\n",
    "perturbed_tokens, perturbed_tags, perturbed = perturb_possesive_genitive(tokens, tags)\n",
    "print(' '.join(perturbed_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d379525-e665-4eb9-971a-192de753c2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wie alt ist die Frau vom John Stamos ?\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Wie alt ist die Frau von John Stamos ?\"\n",
    "tokens = sentence.split()\n",
    "tags = [\"O\"] * len(tokens)\n",
    "tags[-3] = 'B-person'\n",
    "\n",
    "\n",
    "\n",
    "perturbed_tokens, perturbed_tags, perturbed = perturb_article_before_personal_name(tokens, tags)\n",
    "print(' '.join(perturbed_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3af512c-e9a8-44b5-87bf-e4a2b3d9e888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Ich muss den Papa jetzt anrufen'.\n"
     ]
    }
   ],
   "source": [
    "sentence = \"'Ich muss Papa jetzt anrufen'.\"\n",
    "tokens = sentence.split()\n",
    "tags = [\"O\"] * len(tokens)\n",
    "tags[2] = 'B-person'\n",
    "\n",
    "perturbed_tokens, perturbed_tags, perturbed = perturb_article_before_personal_name(tokens, tags)\n",
    "print(' '.join(perturbed_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7627b33-caa4-4f92-9399-17e3acdd0381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hier ist der Urlaub oft deutlich günstiger wie in Deutschland .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Hier ist der Urlaub oft deutlich günstiger als in Deutschland .\"\n",
    "tokens = sentence.split()\n",
    "tags = [\"O\"] * len(tokens)\n",
    "\n",
    "\n",
    "perturbed_tokens, perturbed_tags, perturbed = perturb_als_in_comparative_constructions(tokens, tags)\n",
    "print(' '.join(perturbed_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c9d7e0c-fbb2-4e93-a811-ace1c989bd90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsere Gäste können es kaum glauben, dass aus einem so einem kleinen Samen ein so ein großer Baum wachsen kann .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Unsere Gäste können es kaum glauben, dass aus einem so kleinen Samen ein so großer Baum wachsen kann .\"\n",
    "tokens = sentence.split()\n",
    "tags = [\"O\"] * len(tokens)\n",
    "\n",
    "perturbed_tokens, perturbed_tags, perturbed = perturb_double_article(tokens, tags)\n",
    "print(' '.join(perturbed_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8021c65-fc12-4512-ab0e-74a3e26f95c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seit', 'wann', 'ist', 'prinzessin', 'kate', 'schwanger', '.']\n",
      "seit wann ist prinzessin kate schwanger .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"seit wann ist prinzessin kate schwanger .\"\n",
    "tokens = sentence.split()\n",
    "tags = [\"O\"] * len(tokens)\n",
    "tags[3] = 'B-person'\n",
    "tags[4] = 'I-person'\n",
    "# tags[2] = 'I-person'\n",
    "\n",
    "perturbed_tokens, perturbed_tags, perturbed = perturb_swap_name(tokens, tags)\n",
    "print(perturbed_tokens)\n",
    "print(' '.join(perturbed_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02efe05e-829a-4ee7-b714-a5b47e4c4504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "habe ich denn irgendwelche eingehenden emails ?\n"
     ]
    }
   ],
   "source": [
    "sentence = \"habe ich irgendwelche eingehenden emails ?\"\n",
    "tokens = sentence.split()\n",
    "tags = [\"O\"] * len(tokens)\n",
    "\n",
    "perturbed_tokens, perturbed_tags, perturbed = perturb_denn_in_questions(tokens, tags)\n",
    "print(' '.join(perturbed_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18613a51-5964-47b6-90c8-1760d11e513a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diese letzte email muss sofort werden beantwortet\n"
     ]
    }
   ],
   "source": [
    "sentence = \"diese letzte email muss sofort beantwortet werden\"\n",
    "tokens = sentence.split()\n",
    "tags = [\"O\"] * len(tokens)\n",
    "\n",
    "perturbed_tokens, perturbed_tags, perturbed = perturb_2_verb_clusters(tokens, tags)\n",
    "print(' '.join(perturbed_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdb291d4-e0d6-413c-93c4-deb499a9b94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ich bin am essen .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Ich esse .\"\n",
    "tokens = sentence.split()\n",
    "tags = [\"O\"] * len(tokens)\n",
    "\n",
    "perturbed_tokens, perturbed_tags, perturbed = perturb_am_infinitive(tokens, tags)\n",
    "print(' '.join(perturbed_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "613293a5-4baf-4cf6-b78c-2138184e6820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "da weiß ich nichts von .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Davon weiß ich nichts .\"\n",
    "tokens = sentence.split()\n",
    "tags = [\"O\"] * len(tokens)\n",
    "\n",
    "perturbed_tokens, perturbed_tags, perturbed = perturb_da(tokens, tags)\n",
    "print(' '.join(perturbed_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e24e0e57-b929-48ba-84a4-ece1f669cfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auf der Suche nach günstigen Bahntickets auf München? .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Auf der Suche nach günstigen Bahntickets nach München? .\"\n",
    "tokens = sentence.split()\n",
    "tags = [\"O\"] * len(tokens)\n",
    "\n",
    "perturbed_tokens, perturbed_tags, perturbed = perturb_nach(tokens, tags)\n",
    "print(' '.join(perturbed_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "634b5637-597e-47ce-9b3d-261e26004f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Willkommen zu München .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Willkommen in München .\"\n",
    "tokens = sentence.split()\n",
    "tags = [\"O\"] * len(tokens)\n",
    "\n",
    "perturbed_tokens, perturbed_tags, perturbed = perturb_in(tokens, tags)\n",
    "print(' '.join(perturbed_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c38122f2-95d0-46f5-89f7-15f8ada6d8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es gibt keine Person nicht auf der Welt, die nein zu Ihnen sagen kann .\n",
      "['O', 'O', 'O', 'B-Per', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Es gibt keine Person auf der Welt, die nein zu Ihnen sagen kann .\" \n",
    "tokens = sentence.split()\n",
    "tags = [\"O\"] * len(tokens)\n",
    "tags[3] = \"B-Per\"\n",
    "\n",
    "perturbed_tokens, perturbed_tags, perturbed = perturb_negative_concord(tokens, tags)\n",
    "print(' '.join(perturbed_tokens))\n",
    "print(perturbed_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71166be6-8969-4987-abc5-25538215fb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Stern , wo leuchtet , der Stern , wo funkelt , so wird's seit ewiger Zeit schon gemunkelt .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Der Stern , der leuchtet , der Stern , der funkelt , so wird's seit ewiger Zeit schon gemunkelt .\"\n",
    "tokens = sentence.split()\n",
    "tags = [\"O\"] * len(tokens)\n",
    "\n",
    "perturbed_tokens, perturbed_tags, perturbed = perturb_relative_pronoun(tokens, tags)\n",
    "print(' '.join(perturbed_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6521abf-4112-4ff6-8cdb-cd0d2ef29f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es hat noch Brot .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Es gibt noch Brot .\"\n",
    "tokens = sentence.split()\n",
    "tags = [\"O\"] * len(tokens)\n",
    "\n",
    "perturbed_tokens, perturbed_tags, perturbed = perturb_existential_clause(tokens, tags)\n",
    "print(' '.join(perturbed_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0ae165a-3e16-41c9-b1ca-40534455e332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gibt's noch Brot ?\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Gibt es noch Brot ?\"\n",
    "tokens = sentence.split()\n",
    "tags = [\"O\"] * len(tokens)\n",
    "\n",
    "perturbed_tokens, perturbed_tags, perturbed = perturb_contracted_verb_and_pronoun(tokens, tags)\n",
    "print(' '.join(perturbed_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ad60660-8bb9-4fa6-a4da-eb2a0e262152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ich hab\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Ich habe\"\n",
    "tokens = sentence.split()\n",
    "tags = [\"O\"] * len(tokens)\n",
    "\n",
    "perturbed_tokens, perturbed_tags, perturbed = perturb_schwa_elision_in_verbs(tokens, tags)\n",
    "print(' '.join(perturbed_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98bf6cc6-6b96-407f-9d43-9957f2b3b166",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "generator raised StopIteration",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/mounts/work/artemova/miniconda3/envs/ahava/lib/python3.10/site-packages/Pattern-3.6-py3.10.egg/pattern/text/__init__.py:609\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(path, encoding, comment)\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m line\n\u001b[0;32m--> 609\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[0;31mStopIteration\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m tokens \u001b[38;5;241m=\u001b[39m sentence\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m      3\u001b[0m tags \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(tokens)\n\u001b[0;32m----> 6\u001b[0m perturbed_tokens, perturbed_tags, perturbed \u001b[38;5;241m=\u001b[39m \u001b[43mperturb_tun_imperativ\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(perturbed_tokens))\n",
      "File \u001b[0;32m/mounts/work/artemova/dialect-robust/dialect_perturbations.py:851\u001b[0m, in \u001b[0;36mperturb_tun_imperativ\u001b[0;34m(tokens, tags)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_imperativ \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokens, tags, replaced\n\u001b[0;32m--> 851\u001b[0m verb \u001b[38;5;241m=\u001b[39m \u001b[43mconjugate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mINFINITIVE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokens[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mschalte\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    853\u001b[0m     verb \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mschalten\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/mounts/work/artemova/miniconda3/envs/ahava/lib/python3.10/site-packages/Pattern-3.6-py3.10.egg/pattern/text/__init__.py:2208\u001b[0m, in \u001b[0;36mVerbs.conjugate\u001b[0;34m(self, verb, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2206\u001b[0m i2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mid\u001b[39m))\n\u001b[1;32m   2207\u001b[0m i3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mid\u001b[39m)))\n\u001b[0;32m-> 2208\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlemma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2209\u001b[0m v \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2210\u001b[0m \u001b[38;5;66;03m# Get the verb lexeme and return the requested index.\u001b[39;00m\n",
      "File \u001b[0;32m/mounts/work/artemova/miniconda3/envs/ahava/lib/python3.10/site-packages/Pattern-3.6-py3.10.egg/pattern/text/__init__.py:2172\u001b[0m, in \u001b[0;36mVerbs.lemma\u001b[0;34m(self, verb, parse)\u001b[0m\n\u001b[1;32m   2169\u001b[0m \u001b[38;5;124;03m\"\"\" Returns the infinitive form of the given verb, or None.\u001b[39;00m\n\u001b[1;32m   2170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2172\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verb\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inverse:\n\u001b[1;32m   2174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inverse[verb\u001b[38;5;241m.\u001b[39mlower()]\n",
      "File \u001b[0;32m/mounts/work/artemova/miniconda3/envs/ahava/lib/python3.10/site-packages/Pattern-3.6-py3.10.egg/pattern/text/__init__.py:2127\u001b[0m, in \u001b[0;36mVerbs.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2125\u001b[0m     \u001b[38;5;66;03m# have,,,has,,having,,,,,had,had,haven't,,,hasn't,,,,,,,hadn't,hadn't\u001b[39;00m\n\u001b[1;32m   2126\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format[TENSES_ID[INFINITIVE]]\n\u001b[0;32m-> 2127\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m _read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path):\n\u001b[1;32m   2128\u001b[0m         v \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2129\u001b[0m         \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, v[\u001b[38;5;28mid\u001b[39m], v)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: generator raised StopIteration"
     ]
    }
   ],
   "source": [
    "sentence = \"erinnere mich an notwendige veranstaltungen\"\n",
    "tokens = sentence.split()\n",
    "tags = [\"O\"] * len(tokens)\n",
    "\n",
    "\n",
    "perturbed_tokens, perturbed_tags, perturbed = perturb_tun_imperativ(tokens, tags)\n",
    "print(' '.join(perturbed_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a036b4-a2cb-4db5-873c-11a3f47da93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_group_perturbations = [perturb_genitive_to_dativ,\n",
    "                            perturb_possesive_genitive,\n",
    "                            perturb_article_before_personal_name,\n",
    "                            perturb_als_in_comparative_constructions,\n",
    "                            perturb_double_article]\n",
    "\n",
    "discourse_and_word_order_perturbations = [perturb_swap_name,\n",
    "                                          perturb_denn_in_questions,\n",
    "                                          perturb_2_verb_clusters]\n",
    "\n",
    "tense_and_aspect_perturbations = [perturb_am_infinitive]\n",
    "\n",
    "adverbs_and_prepositon_perturbations = [perturb_da,\n",
    "                                        perturb_in,\n",
    "                                        perturb_nach]\n",
    "\n",
    "negation_perturbations = [perturb_negative_concord]\n",
    "\n",
    "relativization_perturbations = [perturb_relative_pronoun]\n",
    "\n",
    "complementation_perturbations = [perturb_existential_clause]\n",
    "\n",
    "other_perturbations = [perturb_contracted_verb_and_pronoun, \n",
    "                       perturb_schwa_elision_in_verbs, \n",
    "                       perturb_tun_imperativ]\n",
    "\n",
    "\n",
    "perturbations = noun_group_perturbations + discourse_and_word_order_perturbations + tense_and_aspect_perturbations + adverbs_and_prepositon_perturbations + negation_perturbations + relativization_perturbations + complementation_perturbations + other_perturbations\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
